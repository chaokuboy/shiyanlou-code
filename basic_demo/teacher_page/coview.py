import os
import streamlit as st
from zhipuai import ZhipuAI

st.set_page_config(
    page_title="æ™ºæ±‡ä¸­åŒ»",
    page_icon="ğŸ§Š",
    layout="wide"
)


st.subheader('æ™ºæ±‡ä¸­åŒ»')
st.markdown("***æ™ºæ±‡ä¸­åŒ»æ•™è‚²ï¼Œå¼€å¯æ™ºæ…§ä¹‹æ—…ï¼Œæˆå°±æœªæ¥ä¹‹æ˜Ÿ***:+1: ***æ™ºæ±‡ä¸­åŒ»ç‚¹äº®æ‚¨å‰è¡Œçš„è·¯***.:sunglasses:")


if "history" not in st.session_state:
    st.session_state.history = [{"role":"user","content":"ä½ å¥½ï¼"},{"role":"assistant","content":"ä½ å¥½ğŸ‘‹ï¼æˆ‘æ˜¯æ™ºæ±‡ä¸­åŒ»æ•™è‚²æ•™è‚²åŠ©æ‰‹å­¦é€”AIï¼Œå¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæ¬¢è¿é—®æˆ‘ä»»ä½•é—®é¢˜ã€‚"}]
if "past_key_values" not in st.session_state:
    st.session_state.past_key_values = None

max_length =8192
top_p =0.8
temperature=0.6
st.sidebar.title("æ™ºèƒ½ç­”ç–‘")
option = st.sidebar.selectbox(
    '**æ‚¨æƒ³ä½¿ç”¨çš„æ¨¡å‹åŠ©æ‰‹ï¼Ÿ**',
    ('å›¾åƒåŠ©æ‰‹', 'æ–‡æœ¬åŠ©æ‰‹',))
if option=='æ–‡æœ¬åŠ©æ‰‹':
    st.switch_page("web_demo_streamlit.py")

uploaded_file = st.sidebar.file_uploader("ä¸Šä¼ ä¸€å¼ å›¾åƒ",help="é€‰æ‹©ä¸€å¼ .jpgæˆ–.png")

image_url=st.sidebar.text_input("æˆ–è€…è¯·è¾“å…¥å›¾ç‰‡çš„ç½‘ç»œåœ°å€æˆ–base64ç¼–ç ")
buttonClean = st.sidebar.button("æ¸…ç†å†å²ä¼šè¯", key="clean")
if buttonClean:
    st.session_state.history = []
    st.session_state.past_key_values = None
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
    st.rerun()

for i, message in enumerate(st.session_state.history):
    if message["role"] == "user":
        with st.chat_message(name="user", avatar="ğŸ§‘"):
            st.markdown(message["content"])
    else:
        with st.chat_message(name="assistant", avatar="ğŸ§Š"):
            st.markdown(message["content"])

with st.chat_message(name="user", avatar="ğŸ§‘"):
    input_placeholder = st.empty()
with st.chat_message(name="assistant", avatar="ğŸ§Š"):
    message_placeholder = st.empty()

prompt_text = st.chat_input("è¯·è¾“å…¥æ‚¨åˆ†æå›¾ç‰‡çš„é—®é¢˜")

client = ZhipuAI(api_key="8289e6c898ff7b3a2cf6d4c2eaf2d9da.TEAA1e32bM6clWc2") # å¡«å†™æ‚¨è‡ªå·±çš„APIKey

if prompt_text and image_url:
    input_placeholder.markdown(prompt_text)
    history = st.session_state.history
    past_key_values = st.session_state.past_key_values
    response = client.chat.completions.create(
    model="glm-4v",  # å¡«å†™éœ€è¦è°ƒç”¨çš„æ¨¡å‹åç§°
    messages=[
       {
        "role": "user",
        "content": [
          {
            "type": "text",
            "text": prompt_text
          },
          {
            "type": "image_url",
            "image_url": {
                "url" : image_url
            }
          }
        ]
      }
    ]
)
    message_placeholder.markdown(response.choices[0].message.content)
    st.session_state.history = history
    st.session_state.past_key_values = past_key_values
elif prompt_text:
    input_placeholder.markdown(prompt_text)
    history = st.session_state.history
    past_key_values = st.session_state.past_key_values
    response = client.images.generations(
    model="cogview-3", #å¡«å†™éœ€è¦è°ƒç”¨çš„æ¨¡å‹åç§°
    prompt=prompt_text
    )
    message_placeholder.markdown(response.data[0].url)
    st.session_state.history = history
    st.session_state.past_key_values = past_key_values
st.markdown(f"""<style>
  .stChatFloatingInputContainer{{
    position: fixed;
    bottom: 50px;
    padding-bottom: 0px;
    padding-top: 0em;
    z-index: 99;
    }}
    </style>""",
    unsafe_allow_html=True)

